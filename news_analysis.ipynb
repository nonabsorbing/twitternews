{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do\n",
    "#fix config file \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Import VADER analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "API Keys\n",
    "from config import (consumer_key,\n",
    "                    consumer_secret,\n",
    "                    access_token,\n",
    "                    access_token_secret)\n",
    "\n",
    "\n",
    "\n",
    "# Tweepy block code\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define list of Twitter handles\n",
    "\n",
    "news_users = (\"BBCNews\", \"FoxNews\", \"cbsnews\", \"CNN\", \"nytimes\")\n",
    "\n",
    "# List for dictionaries of results\n",
    "# results_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for holding timestamp\n",
    "name_list=[]\n",
    "timestamp_list = []\n",
    "converted_timestamps = []\n",
    "\n",
    "#variable for holding tweet text \n",
    "text_list = []\n",
    "\n",
    "# Variables for holding sentiments\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_tweet = None\n",
    "\n",
    "# Loop through each user\n",
    "for x in range(1):\n",
    "\n",
    "    #  Loop through 10 pages of tweets (total 100 tweets)\n",
    "    for user in news_users:\n",
    "        \n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(user, page=x)\n",
    "        #do i need to change the loop because I'm not doing pages, just a 100 count?\n",
    "\n",
    "#         public_tweets = api.search(user, \n",
    "#                                    count=10,\n",
    "#                                    result_type=\"recent\", \n",
    "#                                    max_id=oldest_tweet)\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "            #Get news org name\n",
    "            name = (tweet[\"user\"][\"name\"])\n",
    "            \n",
    "            #get raw timestamp\n",
    "            raw_timestamp=(tweet[\"created_at\"])\n",
    "            converted_time = datetime.strptime(raw_timestamp, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "            \n",
    "            tweet_text = (tweet[\"text\"])\n",
    "                               \n",
    "            # Perform a sentiment analysis with the compound, positive, neutral, and \n",
    "            # negative scoring for each tweet.\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "             \n",
    "           # Add each value to the appropriate list\n",
    "                   \n",
    "            name_list.append(name)\n",
    "            timestamp_list.append(converted_time )\n",
    "            text_list.append(tweet_text)\n",
    "            compound_list.append(compound)\n",
    "            positive_list.append(pos)\n",
    "            negative_list.append(neg)\n",
    "            neutral_list.append(neu)\n",
    "\n",
    "                # Create a dictionary of result\n",
    "\n",
    "            user_results = {\"Username\": name_list,\n",
    "                            \"Timestamp\": timestamp_list,\n",
    "                            \"Tweet Text\" : text_list,\n",
    "                            \"Compound Score\": compound_list,\n",
    "                            \"Postive Score\": positive_list,\n",
    "                            \"Neutral Score\": neutral_list,\n",
    "                            \"Negative Score\": negative_list\n",
    "                             }\n",
    "# * Pull into a DataFrame the tweet's source account, its text, its date, and \n",
    "# its compound, positive, neutral, and negative sentiment scores.\n",
    "            \n",
    "            \n",
    "data_final = pd.DataFrame(user_results)\n",
    "\n",
    "data_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = data_final.sort_values(\"Timestamp\")\n",
    "data_sorted.to_csv(\"tweetdata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYTimes_data = data_sorted[(data_sorted[\"Username\"]==\"The New York Times\")]\n",
    "BBC_data = data_sorted[(data_sorted[\"Username\"]==\"BBC News (UK)\")]\n",
    "CBS_data = data_sorted[(data_sorted[\"Username\"]==\"CBS News\")]\n",
    "CNN_data = data_sorted[(data_sorted[\"Username\"]==\"CNN\")]\n",
    "FoxNews_data = data_sorted[(data_sorted[\"Username\"]==\"Fox News\")]\n",
    "\n",
    "\n",
    "plt.scatter(NYTimes_data[\"Timestamp\"], NYTimes_data[\"Compound Score\"], label = \"NYT\", color = \"gray\")\n",
    "plt.scatter(BBC_data[\"Timestamp\"], BBC_data[\"Compound Score\"], label = \"BBC\", color = \"green\")\n",
    "plt.scatter(CBS_data[\"Timestamp\"], CBS_data[\"Compound Score\"], label = \"CBS\", color = \"blue\")\n",
    "plt.scatter(CNN_data[\"Timestamp\"], CNN_data[\"Compound Score\"], label = \"CNN\", color = \"orange\")\n",
    "plt.scatter(FoxNews_data[\"Timestamp\"], FoxNews_data[\"Compound Score\"], label = \"FoxNews\", color = \"red\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The first plot will be and/or feature the following:\n",
    "# # * Be a scatter plot of sentiments of the last **100** tweets sent out\n",
    "# by each news organization, ranging from -1.0 to 1.0, where a score of 0 \n",
    "# expresses a neutral sentiment, -1 the most negative sentiment possible, \n",
    "# and +1 the most positive sentiment possible.\n",
    "# # # * Each plot point will reflect the _compound_ sentiment of a tweet.\n",
    "# # # * Sort each plot point by its relative timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second plot will be a bar plot visualizing the\n",
    "# _overall_ sentiments of the last 100 tweets from each organization. \n",
    "# For this plot, you will again aggregate the compound sentiments \n",
    "# analyzed by VADER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Export the data in the DataFrame into a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Save PNG images for each plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
